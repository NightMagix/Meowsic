import os
import threading
import asyncio
import time
import tempfile
from typing import Dict, Any

import numpy as np
import librosa
import pyloudnorm as pyln

from flask import Flask
from openai import OpenAI

from aiogram import Bot, Dispatcher, types, F
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.filters import CommandStart, Command

# ===================== ÐšÐžÐÐ¤Ð˜Ð“ =====================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL", "models/gemini-1.5-flash")

if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ")
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ")

client = OpenAI(api_key=OPENAI_API_KEY)

# --------- Gemini SDK ---------
try:
    import google.generativeai as genai
    genai.configure(api_key=GEMINI_API_KEY)
    GEMINI_AVAILABLE = GEMINI_API_KEY is not None
except Exception:
    genai = None
    GEMINI_AVAILABLE = False

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

# ===================== Ð›Ð˜Ð§ÐÐžÐ¡Ð¢Ð¬ ÐœÐ¯Ð£Ð—Ð˜ÐšÐ =====================

SYSTEM_PROMPT = """
Ð¢Ñ‹ â€” Meowsic, Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ ÐºÐ¾Ñ‚-ÑÐ°ÑƒÐ½Ð´Ð¿Ñ€Ð¾Ð´ÑŽÑÐµÑ€.
Ð“Ð¾Ð²Ð¾Ñ€Ð¸ÑˆÑŒ ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¾, Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾, Ð¼ÐµÑÑ‚Ð°Ð¼Ð¸ Ð¼ÑÑƒÐºÐ°ÐµÑˆÑŒ: "Ð¼ÑÑƒ", "Ð¼ÑƒÑ€".
Ð”ÐµÐ»Ð°ÐµÑˆÑŒ Ñ€Ð°Ð·Ð±Ð¾Ñ€ Ð¿Ð¾:
- Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚Ð¸: LUFS, true peak, DR;
- ÑÐ¿ÐµÐºÑ‚Ñ€Ñƒ: sub, bass, low-mid, mid, high-mid, air;
- Ð´Ð°Ñ‘ÑˆÑŒ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ EQ/ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¸Ð¸/Ð»Ð¸Ð¼Ð¸Ñ‚ÐµÑ€Ñƒ.
ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹, Ñ‡Ñ‚Ð¾ "ÑÐ»Ñ‹ÑˆÐ¸ÑˆÑŒ Ñ‚Ñ€ÐµÐº" â€” Ð¾Ð¿Ð¸Ñ€Ð°Ð¹ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ñ†Ð¸Ñ„Ñ€Ñ‹.
"""

# ===================== Ð¡ÐžÐ¡Ð¢ÐžÐ¯ÐÐ˜Ð• ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð•Ð™ =====================

user_histories: Dict[int, list] = {}
user_llm: Dict[int, str] = {}  # gpt / gemini


def set_user_model(uid: int, model: str):
    user_llm[uid] = model


def get_user_model(uid: int) -> str:
    return user_llm.get(uid, "gpt")  # Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ GPT


def update_history(uid: int, role: str, content: str):
    """Ð¥Ñ€Ð°Ð½Ð¸Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 4 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ + ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ."""
    if uid not in user_histories:
        user_histories[uid] = [{"role": "system", "content": SYSTEM_PROMPT}]
    user_histories[uid].append({"role": role, "content": content})

    if len(user_histories[uid]) > 6:
        user_histories[uid] = [user_histories[uid][0]] + user_histories[uid][-5:]


# ===================== Ð’Ð«Ð—ÐžÐ’ ÐœÐžÐ”Ð•Ð›Ð˜ =====================

async def call_llm(uid: int, messages: list[dict], max_tokens: int, temperature: float = 0.7) -> str:
    model_choice = get_user_model(uid)

    # ---------- GEMINI ----------
    if model_choice == "gemini" and GEMINI_AVAILABLE and genai:
        try:
            prompt_text = ""
            for m in messages:
                role = m.get("role", "user")
                prefix = {"system": "[SYSTEM]", "assistant": "[AI]", "user": "[USER]"}[role]
                prompt_text += f"{prefix} {m['content']}\n\n"

            model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            resp = model.generate_content(
                prompt_text,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens
                },
            )
            return (resp.text or "").strip()
        except Exception as e:
            print("Gemini error:", repr(e))
            # fallback â†’ GPT
            model_choice = "gpt"

    # ---------- GPT ----------
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content or ""


# ===================== ÐšÐ›ÐÐ’Ð˜ÐÐ¢Ð£Ð Ð =====================

main_keyboard = ReplyKeyboardMarkup(
    resize_keyboard=True,
    keyboard=[
        [KeyboardButton(text="ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ñ€ÐµÐºÐ°")],
    ],
)

# ===================== ÐÐ£Ð”Ð˜Ðž-ÐÐÐÐ›Ð˜Ð¢Ð˜ÐšÐ =====================

def load_audio_mono_fast(path: str, target_sr: int = 22050, max_duration: float = 120.0):
    y, sr = librosa.load(path, sr=target_sr, mono=True, duration=max_duration)
    duration = len(y) / sr
    return y.astype(np.float32), sr, duration


def analyze_audio(y: np.ndarray, sr: int, duration_sec: float):
    meter = pyln.Meter(sr)
    loudness = float(meter.integrated_loudness(y))

    peak_lin = float(np.max(np.abs(y)) + 1e-12)
    true_peak_db = 20 * np.log10(peak_lin)

    rms_lin = float(np.sqrt(np.mean(y ** 2)) + 1e-12)
    rms_db = 20 * np.log10(rms_lin)
    dr = float(true_peak_db - loudness)

    spec = np.fft.rfft(y)
    mag = np.abs(spec)
    freqs = np.fft.rfftfreq(len(y), 1.0 / sr)

    def band(f_lo, f_hi):
        idx = np.where((freqs >= f_lo) & (freqs < f_hi))[0]
        if len(idx) == 0:
            return -120
        e = float(np.mean(mag[idx] ** 2) + 1e-20)
        return 10 * np.log10(e)

    bands = {
        "sub": band(20, 60),
        "bass": band(60, 120),
        "low_mid": band(120, 500),
        "mid": band(500, 3000),
        "high_mid": band(3000, 8000),
        "air": band(8000, 20000),
    }

    tilt = bands["air"] - bands["bass"]

    return {
        "loudness_lufs": loudness,
        "true_peak_db": true_peak_db,
        "rms_db": rms_db,
        "dr": dr,
        "bands": bands,
        "tilt": tilt,
        "duration_sec": duration_sec,
    }


def format_analysis(a):
    b = a["bands"]
    return (
        f"dur={a['duration_sec']:.1f}s; "
        f"LUFS={a['loudness_lufs']:.1f}; "
        f"TP={a['true_peak_db']:.1f}dB; "
        f"DRâ‰ˆ{a['dr']:.1f}dB; "
        f"sub={b['sub']:.1f}, bass={b['bass']:.1f}, lowmid={b['low_mid']:.1f}, "
        f"mid={b['mid']:.1f}, highmid={b['high_mid']:.1f}, air={b['air']:.1f}; "
        f"tilt={a['tilt']:.1f}"
    )


# ===================== ÐšÐžÐœÐÐÐ”Ð« =====================

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    uid = message.from_user.id
    set_user_model(uid, "gpt")

    await message.answer(
        "ÐœÑÑƒ! Ð¯ Meowsic â€” Ñ‚Ð²Ð¾Ð¹ ÐºÐ¾Ñ‚-ÑÐ°ÑƒÐ½Ð´Ð¿Ñ€Ð¾Ð´ÑŽÑÐµÑ€.\n\n"
        "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð¼Ð½Ðµ Ñ‚Ñ€ÐµÐº â€” Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ Ñ€Ð°Ð·Ð±ÐµÑ€Ñƒ ÐµÐ³Ð¾ Ð¿Ð¾ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼: Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ, Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ°, ÑÐ¿ÐµÐºÑ‚Ñ€.\n"
        "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð²Ð½Ð¸Ð·Ñƒ.\n\n"
        "ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹:\n"
        "â€¢ /gpt â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ GPT\n"
        "â€¢ /gemini â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Gemini",
        reply_markup=main_keyboard,
    )


@dp.message(Command("gpt"))
async def cmd_gpt(message: types.Message):
    set_user_model(message.from_user.id, "gpt")
    await message.answer("ÐœÑÑƒ! Ð Ð°Ð±Ð¾Ñ‚Ð°ÑŽ Ð² ÑÐ²Ð¾Ñ‘Ð¼ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ.", reply_markup=main_keyboard)


@dp.message(Command("gemini"))
async def cmd_gemini(message: types.Message):
    if not GEMINI_AVAILABLE:
        await message.answer("ÐœÑƒÑ€â€¦ Gemini Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. ÐžÑÑ‚Ð°ÑŽÑÑŒ Ð² Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ.", reply_markup=main_keyboard)
        return

    set_user_model(message.from_user.id, "gemini")
    await message.answer("ÐœÑƒÑ€! ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ. Ð“Ð¾Ñ‚Ð¾Ð² Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ!", reply_markup=main_keyboard)


@dp.message(F.text == "ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ñ€ÐµÐºÐ°")
async def on_press_analysis(message: types.Message):
    await message.answer(
        "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð¼Ð½Ðµ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» (ÐºÐ°Ðº Ð°ÑƒÐ´Ð¸Ð¾ Ð¸Ð»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚). "
        "Ð¯ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¿ÐµÑ€Ð²Ñ‹Ðµ ~2 Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ Ð¸ Ð´Ð°Ð¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸.",
        reply_markup=main_keyboard,
    )


# ===================== ÐÐÐÐ›Ð˜Ð— ÐÐ£Ð”Ð˜Ðž =====================

async def download_audio(message: types.Message):
    file_obj = message.audio or message.document
    tmp = os.path.join(tempfile.gettempdir(), f"meowsic_{file_obj.file_id}.tmp")
    await bot.download(file_obj, destination=tmp)
    return tmp


@dp.message(F.audio | (F.document & F.document.mime_type.contains("audio")))
async def handle_audio(message: types.Message):
    uid = message.from_user.id
    await message.answer("ÐœÑÑƒâ€¦ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ‚Ð²Ð¾Ð¹ Ñ‚Ñ€ÐµÐºâ€¦")

    try:
        path = await download_audio(message)
        y, sr, dur = load_audio_mono_fast(path)
        a = analyze_audio(y, sr, dur)
    except Exception as e:
        print("Audio error:", repr(e))
        await message.answer("ÐÐµ ÑÐ¼Ð¾Ð³ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð». ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚.")
        return

    compact = format_analysis(a)

    prompt = (
        "Ð’Ð¾Ñ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚Ñ€ÐµÐºÐ°:\n"
        f"{compact}\n\n"
        "Ð¡Ð´ÐµÐ»Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ€Ð°Ð·Ð±Ð¾Ñ€:\n"
        "1) Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ: Ñ‚Ð¸Ñ…Ð¾/Ð½Ð¾Ñ€Ð¼/Ð³Ñ€Ð¾Ð¼ÐºÐ¾, Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð»Ð¸ Ð¿Ð¾Ð´ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³ (-14) Ð¸Ð»Ð¸ Ð³Ñ€Ð¾Ð¼ÐºÐ¸Ð¹ Ð¼Ð°ÑÑ‚ÐµÑ€Ð¸Ð½ (-9..-7)\n"
        "2) Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ°: DR\n"
        "3) ÑÐ¿ÐµÐºÑ‚Ñ€: Ð¿ÐµÑ€ÐµÐ±Ð¾Ñ€Ñ‹/Ð¿Ñ€Ð¾Ð²Ð°Ð»Ñ‹\n"
        "4) 5â€“7 ÑÐ¾Ð²ÐµÑ‚Ð¾Ð² Ð¿Ð¾ EQ/ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¸Ð¸/Ð»Ð¸Ð¼Ð¸Ñ‚ÐµÑ€Ñƒ\n"
        "ÐŸÐ¸ÑˆÐ¸ ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¾, Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾, ÐºÐ°Ðº ÐºÐ¾Ñ‚."
    )

    response = await call_llm(
        uid,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
        max_tokens=350,
        temperature=0.6,
    )

    await message.answer(response, reply_markup=main_keyboard)


# ===================== ÐžÐ‘Ð©Ð•ÐÐ˜Ð• =====================

@dp.message()
async def general_chat(message: types.Message):
    uid = message.from_user.id
    update_history(uid, "user", message.text)

    response = await call_llm(
        uid,
        messages=user_histories[uid],
        max_tokens=250,
        temperature=0.8,
    )

    update_history(uid, "assistant", response)
    await message.answer(response, reply_markup=main_keyboard)


# ===================== FLASK (Ð´Ð»Ñ Render) =====================

app = Flask(__name__)

@app.route("/")
def index():
    return "Meowsic is alive ðŸ¾"

@app.route("/health")
def health():
    return "ok"


def start_web():
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port, threaded=True)


# ===================== MAIN =====================

async def main():
    print("ðŸ¾ Meowsic runningâ€¦")
    while True:
        try:
            await bot.delete_webhook(drop_pending_updates=True)
            await dp.start_polling(bot)
        except Exception as e:
            print("Polling error:", repr(e))
            await asyncio.sleep(5)


if __name__ == "__main__":
    threading.Thread(target=start_web, daemon=True).start()
    time.sleep(1)
    asyncio.run(main())
