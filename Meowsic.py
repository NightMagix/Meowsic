import os
import threading
import asyncio
import time
import tempfile
from typing import Dict, Any

import numpy as np
import librosa
import pyloudnorm as pyln

from flask import Flask
from openai import OpenAI

from aiogram import Bot, Dispatcher, types, F
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.filters import CommandStart, Command

# ==== –ö–û–ù–§–ò–ì ====

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

client = OpenAI(api_key=OPENAI_API_KEY)

# --- Gemini (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ---
try:
    import google.generativeai as genai  # type: ignore
except ImportError:
    genai = None

if GEMINI_API_KEY and genai is not None:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    genai = None  # —á—Ç–æ–±—ã –Ω–∏–∂–µ –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

# ==== –õ–ò–ß–ù–û–°–¢–¨ –ú–Ø–£–ó–ò–ö–ê (–ö–û–†–û–¢–ö–ê–Ø) ====

SYSTEM_PROMPT = """
–¢—ã ‚Äî Meowsic, —Ü–∏—Ñ—Ä–æ–≤–æ–π –∫–æ—Ç-—Å–∞—É–Ω–¥–ø—Ä–æ–¥—é—Å–µ—Ä.
–ö—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –æ–±—ä—è—Å–Ω—è–µ—à—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–∫–∞:
- –≥—Ä–æ–º–∫–æ—Å—Ç—å: LUFS, true peak, DR;
- —Å–ø–µ–∫—Ç—Ä: –Ω–∏–∑, –Ω–∏–∑-—Å—Ä–µ–¥–∏–Ω–∞, —Å—Ä–µ–¥–∏–Ω–∞, –≤–µ—Ä—Ö–Ω—è—è —Å–µ—Ä–µ–¥–∏–Ω–∞, –≤–æ–∑–¥—É—Ö;
- –¥–∞—ë—à—å –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –ø–æ —ç–∫–≤–∞–ª–∏–∑–∞—Ü–∏–∏, –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –∏ –ª–∏–º–∏—Ç–µ—Ä—É.
–í—Å–µ–≥–¥–∞ –æ–ø–∏—Ä–∞–µ—à—å—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞—è, —á—Ç–æ —Ç—ã "—Å–ª—ã—à–∏—à—å" —Ç—Ä–µ–∫.
–ü–∏—à–∏ –∫–æ–º–ø–∞–∫—Ç–Ω–æ, –º–∞–∫—Å–∏–º—É–º –æ–∫–æ–ª–æ 1200‚Äì1500 —Å–∏–º–≤–æ–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏.
–ò–Ω–æ–≥–¥–∞ –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–ª—è—Ç—å –∫–æ—à–∞—á—å–∏ –≤—Å—Ç–∞–≤–∫–∏ "–º—è—É", "–º—É—Ä", –Ω–æ –±–µ–∑ –ø–µ—Ä–µ–≥—Ä—É–∑–∞.
"""

# ==== –•–†–ê–ù–ï–ù–ò–ï –ò–°–¢–û–†–ò–ò –ò –í–´–ë–û–† –ú–û–î–ï–õ–ò ====

user_histories: Dict[int, list] = {}
user_llm: Dict[int, str] = {}  # "gpt" –∏–ª–∏ "gemini"


def get_user_model(uid: int) -> str:
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é GPT
    return user_llm.get(uid, "gpt")


def set_user_model(uid: int, model: str):
    user_llm[uid] = model


def update_history(uid: int, role: str, content: str):
    if uid not in user_histories:
        user_histories[uid] = [{"role": "system", "content": SYSTEM_PROMPT}]
    user_histories[uid].append({"role": role, "content": content})
    # —Å–∏—Å—Ç–µ–º–Ω–æ–µ + –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è
    if len(user_histories[uid]) > 6:
        user_histories[uid] = [user_histories[uid][0]] + user_histories[uid][-5:]


async def call_llm(
    uid: int,
    messages: list[dict],
    max_tokens: int,
    temperature: float = 0.7,
) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ LLM:
    - –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª /gemini –∏ –µ—Å—Ç—å –∫–ª—é—á + –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini;
    - –∏–Ω–∞—á–µ ‚Äî GPT-4.1-mini.
    """
    model_choice = get_user_model(uid)

    # ----- Gemini -----
    if model_choice == "gemini" and genai is not None and GEMINI_API_KEY:
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º chat-–∏—Å—Ç–æ—Ä–∏—é –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É.
        parts = []
        for m in messages:
            role = m.get("role", "user")
            content = m.get("content", "")
            if not content:
                continue
            if role == "system":
                prefix = "[SYSTEM]"
            elif role == "assistant":
                prefix = "[ASSISTANT]"
            else:
                prefix = "[USER]"
            parts.append(f"{prefix} {content}")
        prompt_text = "\n\n".join(parts)

        model = genai.GenerativeModel("gemini-1.5-flash")
        resp = model.generate_content(
            prompt_text,
            generation_config={
                "temperature": temperature,
                "max_output_tokens": max_tokens,
            },
        )
        return (resp.text or "").strip()

    # ----- GPT –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é -----
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content or ""


# ==== –ö–õ–ê–í–ò–ê–¢–£–†–ê ====

main_keyboard = ReplyKeyboardMarkup(
    resize_keyboard=True,
    keyboard=[
        [KeyboardButton(text="–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–∫–∞")],
    ],
)

# ==== –ê–£–î–ò–û-–ê–ù–ê–õ–ò–¢–ò–ö–ê (–ë–´–°–¢–†–ê–Ø) ====

def load_audio_mono_fast(
    path: str,
    target_sr: int = 22050,
    max_duration: float = 120.0,
) -> tuple[np.ndarray, int, float]:
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞: –º–æ–Ω–æ, –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–π SR, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    y, sr = librosa.load(path, sr=target_sr, mono=True, duration=max_duration)
    if y.size == 0:
        raise RuntimeError("–ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª")
    duration = len(y) / sr
    return y.astype(np.float32), sr, float(duration)


def analyze_audio(y: np.ndarray, sr: int, duration_sec: float) -> Dict[str, Any]:
    meter = pyln.Meter(sr)
    loudness = float(meter.integrated_loudness(y))

    peak_lin = float(np.max(np.abs(y)) + 1e-12)
    true_peak_db = 20.0 * np.log10(peak_lin)

    rms_lin = float(np.sqrt(np.mean(y ** 2)) + 1e-12)
    rms_db = 20.0 * np.log10(rms_lin)
    dr = float(true_peak_db - loudness)

    spec = np.fft.rfft(y)
    mag = np.abs(spec)
    freqs = np.fft.rfftfreq(len(y), 1.0 / sr)

    def band_energy_db(f_lo: float, f_hi: float) -> float:
        idx = np.where((freqs >= f_lo) & (freqs < f_hi))[0]
        if idx.size == 0:
            return -120.0
        e = float(np.mean(mag[idx] ** 2) + 1e-20)
        return 10.0 * np.log10(e)

    bands = {
        "sub": (20, 60),
        "bass": (60, 120),
        "low_mid": (120, 500),
        "mid": (500, 3000),
        "high_mid": (3000, 8000),
        "air": (8000, 20000),
    }

    band_db = {name: band_energy_db(*rng) for name, rng in bands.items()}
    tilt = band_db["air"] - band_db["bass"]

    return {
        "loudness_lufs": loudness,
        "true_peak_db": true_peak_db,
        "rms_db": rms_db,
        "dr": dr,
        "bands_db": band_db,
        "tilt_db": tilt,
        "duration_sec": duration_sec,
        "sr": sr,
    }


def format_analysis_compact(analysis: Dict[str, Any]) -> str:
    """–ö–æ–º–ø–∞–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è LLM (–º–∏–Ω–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤)."""
    b = analysis["bands_db"]
    return (
        f"dur_sec={analysis['duration_sec']:.1f}; "
        f"LUFS={analysis['loudness_lufs']:.1f}; "
        f"TP={analysis['true_peak_db']:.1f} dBFS; "
        f"RMS={analysis['rms_db']:.1f} dBFS; "
        f"DR‚âà{analysis['dr']:.1f} dB; "
        f"bands(dB): sub={b['sub']:.1f}, bass={b['bass']:.1f}, "
        f"low_mid={b['low_mid']:.1f}, mid={b['mid']:.1f}, "
        f"high_mid={b['high_mid']:.1f}, air={b['air']:.1f}; "
        f"tilt(Air-Bass)={analysis['tilt_db']:.1f} dB."
    )


# ==== –ö–û–ú–ê–ù–î–´ / –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ====

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    uid = message.from_user.id
    set_user_model(uid, "gpt")  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é GPT
    text = (
        "–ú—è—É! –Ø Meowsic ‚Äî –∫–æ—Ç-—Å–∞—É–Ω–¥–ø—Ä–æ–¥—é—Å–µ—Ä.\n\n"
        "–°–µ–π—á–∞—Å —è —É–º–µ—é –±—ã—Å—Ç—Ä–æ —Ä–∞–∑–±–∏—Ä–∞—Ç—å —Ç–≤–æ–π —Ç—Ä–µ–∫ –ø–æ —Ü–∏—Ñ—Ä–∞–º:\n"
        "‚Ä¢ –≥—Ä–æ–º–∫–æ—Å—Ç—å (LUFS, true peak, DR)\n"
        "‚Ä¢ —Å–ø–µ–∫—Ç—Ä –ø–æ –ø–æ–ª–æ—Å–∞–º\n\n"
        "–ü—Ä–æ—Å—Ç–æ –ø—Ä–∏—à–ª–∏ –º–Ω–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (–∫–∞–∫ –∞—É–¥–∏–æ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç) ‚Äî —è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–µ—Ä–≤—ã–µ ~2 –º–∏–Ω—É—Ç—ã "
        "–∏ –¥–∞–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã –º–æ–¥–µ–ª–µ–π:\n"
        "‚Ä¢ /gpt ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT-4.1-mini\n"
        "‚Ä¢ /gemini ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Gemini (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω GEMINI_API_KEY)"
    )
    await message.answer(text, reply_markup=main_keyboard)


@dp.message(Command("gpt"))
async def cmd_gpt(message: types.Message):
    uid = message.from_user.id
    set_user_model(uid, "gpt")
    await message.answer(
        "–ú—è—É! –¢–µ–ø–µ—Ä—å —è –æ—Ç–≤–µ—á–∞—é —á–µ—Ä–µ–∑ GPT-4.1-mini. –≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∂–∏–º.",
        reply_markup=main_keyboard,
    )


@dp.message(Command("gemini"))
async def cmd_gemini(message: types.Message):
    uid = message.from_user.id
    if genai is None or not GEMINI_API_KEY:
        await message.answer(
            "–ú—É—Ä‚Ä¶ Gemini —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–ª–∏ GEMINI_API_KEY). "
            "–û—Å—Ç–∞—é—Å—å –Ω–∞ GPT-4.1-mini.",
            reply_markup=main_keyboard,
        )
        return
    set_user_model(uid, "gemini")
    await message.answer(
        "–ú—É—Ä! –¢–µ–ø–µ—Ä—å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å —á–µ—Ä–µ–∑ Gemini (gemini-1.5-flash). "
        "–ï—Å–ª–∏ —á—Ç–æ, –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ GPT –º–æ–∂–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π /gpt.",
        reply_markup=main_keyboard,
    )


@dp.message(F.text == "–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–∫–∞")
async def on_analysis_button(message: types.Message):
    await message.answer(
        "–û—Ç–ø—Ä–∞–≤—å —Ç—Ä–µ–∫ –∫–∞–∫ –∞—É–¥–∏–æ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç. –Ø –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≥–æ–Ω—é –ø–µ—Ä–≤—ã–µ ~2 –º–∏–Ω—É—Ç—ã –∏ –¥–∞–º —Å–æ–≤–µ—Ç—ã –ø–æ "
        "–≥—Ä–æ–º–∫–æ—Å—Ç–∏, –¥–∏–Ω–∞–º–∏–∫–µ –∏ —Å–ø–µ–∫—Ç—Ä—É. –ú—É—Ä!",
        reply_markup=main_keyboard,
    )


# ==== –ó–ê–ì–†–£–ó–ö–ê –ê–£–î–ò–û –ò –ê–ù–ê–õ–ò–ó ====

async def download_audio_to_temp(message: types.Message) -> str:
    if message.audio:
        file_obj = message.audio
    elif message.document and message.document.mime_type and "audio" in message.document.mime_type:
        file_obj = message.document
    else:
        raise RuntimeError("–ù–µ—Ç –∞—É–¥–∏–æ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏")

    tmp_dir = tempfile.gettempdir()
    ext = ".ogg"
    if file_obj.file_name and "." in file_obj.file_name:
        ext = "." + file_obj.file_name.split(".")[-1]

    tmp_path = os.path.join(tmp_dir, f"meowsic_{file_obj.file_id}{ext}")
    await bot.download(file_obj, destination=tmp_path)
    return tmp_path


@dp.message(F.audio | (F.document & F.document.mime_type.contains("audio")))
async def on_audio_message(message: types.Message):
    uid = message.from_user.id
    await message.answer("–ú—è—É, —Å–∫–∞—á–∏–≤–∞—é –∏ –∂–º—É —Ç–≤–æ–π —Ç—Ä–µ–∫ –≤ –∞–Ω–∞–ª–∏–∑...")

    try:
        tmp_path = await download_audio_to_temp(message)
        y, sr, dur = load_audio_mono_fast(tmp_path)
        analysis = analyze_audio(y, sr, dur)
    except Exception as e:
        print("Audio processing error:", repr(e))
        await message.answer("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–∫–∏–Ω—å, –º—è—É.")
        return

    compact = format_analysis_compact(analysis)

    prompt = (
        "–í–æ—Ç —á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç—Ä–µ–∫–∞ "
        "(–≥—Ä–æ–º–∫–æ—Å—Ç—å, –¥–∏–Ω–∞–º–∏–∫–∞, —Å–ø–µ–∫—Ç—Ä):\n\n"
        f"{compact}\n\n"
        "–°–¥–µ–ª–∞–π –ö–†–ê–¢–ö–ò–ô —Ä–∞–∑–±–æ—Ä –¥–ª—è –∑–≤—É–∫–æ—Ä–µ–∂–∏—Å—Å—ë—Ä–∞:\n"
        "1) –û—Ü–µ–Ω–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å: —Ç–∏—Ö–æ/–Ω–æ—Ä–º/–≥—Ä–æ–º–∫–æ, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –ø–æ–¥ —Å—Ç—Ä–∏–º–∏–Ω–≥ (‚âà -14 LUFS) "
        "–∏ –ø–æ–¥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≥—Ä–æ–º–∫–∏–π –º–∞—Å—Ç–µ—Ä–∏–Ω (‚âà -9‚Ä¶-7 LUFS).\n"
        "2) –û—Ü–µ–Ω–∏ –¥–∏–Ω–∞–º–∏–∫—É –ø–æ DR: –∑–∞–∂–∞—Ç—ã–π / —Å—Ä–µ–¥–Ω–∏–π / –∂–∏–≤–æ–π.\n"
        "3) –û—Ü–µ–Ω–∏ —Å–ø–µ–∫—Ç—Ä: –≥–¥–µ –ø–µ—Ä–µ–±–æ—Ä –∏–ª–∏ –ø—Ä–æ–≤–∞–ª (sub, bass, low-mid, mid, high-mid, air).\n"
        "4) –î–∞–π 5‚Äì7 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤: –≥–¥–µ –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ–¥–Ω—è—Ç—å/—Å—Ä–µ–∑–∞—Ç—å EQ (–¥–∏–∞–ø–∞–∑–æ–Ω—ã –∏ ¬±–¥–ë), "
        "–Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏—è/–ª–∏–º–∏—Ç–µ—Ä.\n"
        "–ü–∏—à–∏ –æ—á–µ–Ω—å –∫–æ–º–ø–∞–∫—Ç–Ω–æ, –±–µ–∑ –≤–æ–¥—ã, –º–∞–∫—Å–∏–º—É–º 8 –ø—É–Ω–∫—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏."
    )

    try:
        answer = await call_llm(
            uid,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            temperature=0.6,
            max_tokens=350,
        )
        await message.answer(answer, reply_markup=main_keyboard)
    except Exception as e:
        print("LLM error (analysis):", repr(e))
        await message.answer(
            "–ú—É—Ä... —Å –º–æ–¥–µ–ª—å—é —á—Ç–æ-—Ç–æ –Ω–µ —Å—Ä–æ—Å–ª–æ—Å—å (–ª–∏–º–∏—Ç –∏–ª–∏ —Å–µ—Ç—å). –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á—É—Ç—å –ø–æ–∑–∂–µ.",
            reply_markup=main_keyboard,
        )


# ==== –û–ë–´–ß–ù–´–ô –ß–ê–¢ ====

@dp.message()
async def generic_chat(message: types.Message):
    chat_id = message.chat.id
    uid = message.from_user.id
    text = message.text or ""

    await bot.send_chat_action(chat_id, "typing")
    update_history(uid, "user", text)

    try:
        answer = await call_llm(
            uid,
            messages=user_histories[uid],
            temperature=0.8,
            max_tokens=220,
        )
        update_history(uid, "assistant", answer)
        await message.answer(answer, reply_markup=main_keyboard)
    except Exception as e:
        print("LLM error (chat):", repr(e))
        await message.answer(
            "–ú—è—É... —É –º–µ–Ω—è –ª–∞–ø–∫–∏, –º–æ–¥–µ–ª—å —Å–µ–π—á–∞—Å –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.",
            reply_markup=main_keyboard,
        )


# ==== FLASK –î–õ–Ø RENDER ====

app = Flask(__name__)

@app.route("/")
def index():
    return "Meowsic bot is alive üêæ (GPT/Gemini switch)"

@app.route("/health")
def health():
    return "ok"


def start_web():
    port = int(os.environ.get("PORT", 10000))
    print(f"üåê Meowsic: –ø–æ–¥–Ω–∏–º–∞—é –≤–µ–±-—Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    app.run(host="0.0.0.0", port=port, threaded=True)


# ==== MAIN ====

async def main():
    print("üéß Meowsic: –∑–∞–ø—É—Å–∫–∞—é aiogram polling (with GPT/Gemini switch)...")
    while True:
        try:
            await bot.delete_webhook(drop_pending_updates=True)
            await dp.start_polling(
                bot,
                allowed_updates=dp.resolve_used_update_types(),
            )
        except Exception as e:
            print("‚ùå –û—à–∏–±–∫–∞ –≤ polling:", repr(e))
            print("‚è≥ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ polling —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
            await asyncio.sleep(5)


if __name__ == "__main__":
    web_thread = threading.Thread(target=start_web, daemon=True)
    web_thread.start()
    time.sleep(1)
    asyncio.run(main())
